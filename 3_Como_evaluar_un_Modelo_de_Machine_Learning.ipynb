{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5QVhlvS5pM3PGUaW6NkQW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JhonnyLimachi/IA_en_Salud/blob/main/3_Como_evaluar_un_Modelo_de_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img alt=\"Colaboratory logo\" width=\"15%\" src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/novo_logo_bg_claro.png\">\n",
        "\n",
        "#### **Data Science na Prática 4.0**\n",
        "*by [sigmoidal.ai](https://sigmoidal.ai)*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Rv2MVTmwwGJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como evaluar un modelo de *Machine Learning*\n",
        "\n",
        "Ahora que, has construido tu modelo de *Machine Learning*. Después de varias horas haciendo un análisis exploratorio y limpiando los datos, lo has entrenado con tu conjunto de datos y has obtenido los coeficientes \"ideales\". ¿Cuál es el próximo paso?\n",
        "\n",
        "\n",
        "> \"No controlas aquello que no puedes medir.\"\n",
        "\n",
        "\n",
        "<center><img width=\"50%\" src=\"https://images.unsplash.com/photo-1501516069922-a9982bd6f3bd?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1050&q=80\"></center>\n",
        "\n",
        "\n",
        "En realidad, medir resultados y monitorear indicadores no es algo exclusivo de los sistemas militares, sino que es una tarea obligatoria en cualquier actividad, y más aún en modelos de Inteligencia Artificial.\n",
        "\n",
        "Si no sabes cómo está desempeñándose tu algoritmo, puedes terminar comprometiendo los ingresos de una empresa o incluso su imagen.\n",
        "\n",
        "Existen innumerables metodologías, métricas e investigaciones sobre esta etapa de evaluación. Cada día, la frontera de la ciencia avanza un paso. Lo que ayer era el estado del arte, probablemente no lo será en un mes.\n",
        "\n",
        "Quiero presentar aquí una visión general de las métricas más conocidas y utilizadas por la comunidad.\n"
      ],
      "metadata": {
        "id": "6_-EQfepwTHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación de Modelos de Regresión\n",
        "\n",
        "Los Modelos de Regresión buscan prever un valor numérico continuo. Por ejemplo, cuál será el precio de venta de un inmueble o cuál será la facturación esperada para el próximo mes.\n",
        "\n",
        "Cuando estamos usando el *dataset* de test, fazemos a previsão $\\hat{y}_i$ para la $i\\text{-ésima}$ linha, una vez que tenemos el valor real $y_i$, podemos calcular este error de diferentes formas.\n",
        "\n",
        "<center><img width=\"50%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/regressao_loss.png\"></center>\n",
        "\n",
        "\n",
        "En la imagen anterior, considere que la línea representa su modelo de regresión, es decir, la propia predicción. Cada flecha (vector) representa la diferencia entre el valor real y la predicción.\n",
        "\n",
        "Em outras palavras, cada seta representa o quanto você errou naquela previsão específica. Se você medir todas as distâncias entre os pontos e a reta (que é o seu modelo), você vai ter o seu erro, ou ***loss***.\n",
        "\n",
        "En el ejemplo de esta figura, queda claro que el modelo del gráfico de la izquierda \"falla\" mucho más que el modelo del gráfico de la derecha. Es decir, el modelo de la derecha es mejor.\n",
        "\n",
        "De hecho, existen diversas métricas que pueden utilizarse para verificar el desempeño de su modelo. Vamos a echar un vistazo a las principales.\n",
        "\n",
        "### *Mean Absolut Error* - MAE\n",
        "\n",
        "Es el más simple de todos, donde se calcula la media de la magnitud del error para todos los puntos donde realizamos predicciones, sin considerar la dirección.\n",
        "\n",
        "$$MAE = \\frac{1}{m}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$\n",
        "\n",
        "Es la más intuitiva de todas las métricas, ya que observamos la diferencia absoluta entre la predicción y el valor real.\n",
        "\n",
        "El problema con el MAE es que todos los errores individuales se tratan de la misma manera, lo cual puede ser un problema al manejar valores atípicos.\n",
        "\n",
        "### *Mean Squared Error* - MSE\n",
        "\n",
        "El MSE calcula a média de los errores elevados a la segunda potencia.\n",
        "\n",
        "$$MSE = \\frac{1}{m}\\sum_{i=1}^{m}(y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "La ventaja es que los errores más grandes serán penalizados más que los menores, lo que implica que las diferencias menores tendrán menos impacto en la evaluación.\n",
        "\n",
        "Puede haber una dificultad en su interpretación, ya que la unidad de medida será alterada.\n",
        "\n",
        "### *Root Mean Squared Error* - RMSE\n",
        "\n",
        "Calcular la raíz cuadrada de la media de los cuadrados de los errores hace que el RMSE penalice los errores más grandes, siendo más sensible a los valores atípicos.\n",
        "\n",
        "$$RMSE = \\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}(y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "Note que las diferencias se elevan al cuadrado antes de que se calcule su media.\n",
        "\n",
        "Esta métrica es muy deseada en situaciones donde se desea evitar grandes errores al máximo.\n",
        "\n",
        "### *R-Squared* - $R^2$\n",
        "\n",
        "Aunque el R-Squared no se trata propiamente de errores, es bastante popular para verificar la precisión de los modelos de regresión.\n",
        "\n",
        "$$R^2 = 1 - \\frac{\\sum_{j=1}^{m}(y_i - \\hat{y}_i)^2}{\\sum_{j=1}^{m}(y_i - \\bar{y}_i)^2}$$\n",
        "\n",
        "Puedes entender la métrica como \"qué tan bueno es tu modelo en comparación con los valores reales\", y lo hace calculando las varianzas en relación a la media y a la línea recta.\n"
      ],
      "metadata": {
        "id": "yNFEboNgw5xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliando Modelos de Classificação\n",
        "\n",
        "Como se avalia um modelo de classificação?\n",
        "\n",
        "Seja trabalhando com classificação binária ou com diversas classes, as métricas relacionadas a modelos de classificação não podem ser os mesmos que usamos em modelos de regressão.\n",
        "\n",
        "\n",
        "### Acurácia\n",
        "\n",
        "Definitivamente, é a métrica mais intuitiva e fácil para se entender. A acurácia mostra diretamente a porcentagem de acertos do nosso modelo.\n",
        "\n",
        "$$\n",
        "\\text{Acurácia} = \\frac{\\text{Número de previsões corretas}}{\\text{Número total de previsões}}\n",
        "$$\n",
        "\n",
        "Apesar de ser muito direta e intuitiva, a acurácia não é uma boa métrica quando você lida, por exemplo, com dados desbalanceados.\n",
        "\n",
        "Em um *dataset* de fraudes bancárias, o número de eventos classificados como fraude pode ser inferior a 1%. Ou seja, a acurácia do modelo será superior para os casos de não-fraude e não retratará bem a natureza do nosso problema.\n",
        "\n",
        "Nesse exemplo de fraude bancária, o banco irá preferir uma acurácia máxima na detecção de casos confirmados de fraudes, mesmo que tenha diminuir a acurácia global - e ter um número maior de alarmes falsos.\n",
        "\n",
        "Veja um exemplo do curso Machine Learning Crash Course do Google. Nele, pode-se ver com que olhar simplesmente a acurácia pode levar a conclusões erradas. Abaixo, estamos olhando os resultados de um modelo para detecção de tumores malignos.\n",
        "\n",
        "<center><img alt=\"Colaboratory logo\" width=\"50%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/acuracia.png\"></center>\n",
        "\n",
        "Uma acurácia de 91% pode levar a uma interpretação equivocada, pois o modelo conseguiu detectar corretamente apenas 1 dos 9 tumores malignos. Para casos como esses, de dados desbalanceados, o ideal é separar os erros em diferentes tipos, e não apenas usar uma métrica global de acurácia.\n",
        "\n",
        "**Tipos de erros**\n",
        "\n",
        "* **Verdadeiro positivo (*true positive* — TP):** Por exemplo, quando o paciente tem tumor maligno e o modelo classifica como tendo tumor maligno.\n",
        "\n",
        "* **Falso positivo (*false positive* — FP):** Por exemplo, quando o paciente não tem tumor maligno e o modelo classifica como tendo tumor maligno.\n",
        "\n",
        "* **Falso negativo (*true negative* — TN)**: Por exemplo, quando o paciente tem tumor maligno e o modelo classifica como não tendo tumor maligno.\n",
        "\n",
        "* **Verdadeiro negativo (*false negative* — FN):** Por exemplo, quando o paciente não tem tumor maligno e o modelo classifica como não tendo tumor maligno.\n",
        "\n",
        "Com esses conceitos, vamos dar uma olhada em duas outras métricas.\n",
        "\n",
        "### Precision\n",
        "\n",
        "A precisão diz respeito à quantidade (proporcional) de identificações positivas feita corretamente, e é obtida pela equação\n",
        "\n",
        "$$\n",
        "\\frac{TP}{TP+FP}\n",
        "$$\n",
        "\n",
        "Ela responde **\"qual a proporção de identificações positivas que estava correta?\"** Esse valor será máximo (1.0) quando não produzir falsos negativos.\n",
        "\n",
        "No exemplo do tumor maligno, a precisão seria 50%, o que significa que quando o modelo prevê um tumor maligno, está correto metado das vezes.\n",
        "\n",
        "### *Recall*\n",
        "\n",
        "Mostra a proporção de positivos encontrados corretamente. Matematicamente, você calcular o *recall* da seguinte maneira:\n",
        "\n",
        "$$\n",
        "\\frac{TP}{TP+FN}\n",
        "$$\n",
        "\n",
        "No caso do tumor maligno, o recall teria um valor igual a 11%, o que significa que o modelo é capaz de prever corretamente apenas 11% de todos os tumores malignos."
      ],
      "metadata": {
        "id": "hCRMK00_dS3q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3ENgEM4v9CB"
      },
      "outputs": [],
      "source": []
    }
  ]
}